{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMR48C7Xl8JpG9t1kYh64Xa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casanovaalonso/TritonTutorials/blob/main/04_triton_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DHbdSNsDsHc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd80bf5-96fa-4e31-aa0f-362493933278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install triton\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RkECxK4xeL3P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout Regularization\n",
        "\n",
        "Dropout is a technique to prevent overfitting in neural networks by randomly \"dropping out\" (setting to zero) a fraction of neurons during training.\n",
        "\n",
        "### 1. **Forward Pass with Dropout**\n",
        "Each neuron in a layer has a probability $ p $ of being kept:\n",
        "\n",
        "$$\n",
        "d_i \\sim \\text{Bernoulli}(p)\n",
        "$$\n",
        "\n",
        "The activations are then scaled:\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{a}}_l = \\frac{\\mathbf{a}_l \\odot \\mathbf{d}}{(1-p)}\n",
        "$$\n",
        "\n",
        "### 2. **Backpropagation**\n",
        "During backpropagation, the gradients are computed with the dropout mask applied, ensuring correct updates.\n",
        "\n",
        "### 3. **Test Time**\n",
        "At inference time, no neurons are dropped. The output is not scaled, to account for the dropout during training.Ç"
      ],
      "metadata": {
        "id": "bKHzATYXeNWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tabulate\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl"
      ],
      "metadata": {
        "id": "UD-nX-XoeNJB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\")"
      ],
      "metadata": {
        "id": "J1SWssuKlTLS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function will work on 1D tensors\n",
        "@triton.jit\n",
        "def _dropout(\n",
        "    input_ptr,\n",
        "    input_keep_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "  pid = tl.program_id(0)\n",
        "  block_start_ptr = pid * BLOCK_SIZE\n",
        "  offsets = block_start_ptr + tl.arange(0, BLOCK_SIZE)\n",
        "  mask = offsets < n_elements\n",
        "  input = tl.load(input_ptr+offsets, mask=mask)\n",
        "  input_keep = tl.load(input_keep_ptr+offsets, mask=mask)\n",
        "  output = tl.where(input_keep, input/(1-p), 0.0)\n",
        "  tl.store(output_ptr+offsets, output, mask=mask)\n",
        "\n",
        "def dropout(input, input_keep, p):\n",
        "  assert input.device == input_keep.device == DEVICE\n",
        "  assert input.shape == input_keep.shape\n",
        "  assert input.is_contiguous()\n",
        "  assert input_keep.is_contiguous()\n",
        "  n_elements = input.numel()\n",
        "  output = torch.empty_like(input)\n",
        "  grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "  _dropout[grid](\n",
        "      input,\n",
        "      input_keep,\n",
        "      output,\n",
        "      n_elements,\n",
        "      p,\n",
        "      BLOCK_SIZE=1024,\n",
        "  )\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "CmIb6NGAfnmf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input tensor\n",
        "x = torch.randn(size=(10, )).cuda()\n",
        "# Dropout mask\n",
        "p = 0.5\n",
        "x_keep = (torch.rand(size=(10, )) > p).to(torch.int32).cuda()\n",
        "output = dropout(x, input_keep=x_keep, p=p)\n",
        "print(tabulate.tabulate([\n",
        "    [\"input\"] + x.tolist(),\n",
        "    [\"keep mask\"] + x_keep.tolist(),\n",
        "    [\"output\"] + output.tolist(),\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPIxri8lFuZ",
        "outputId": "0d4ce7f8-5e37-44ac-8009-c277443d7a72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------  --------  ---------  --------  --------  -------  --------  ---------  --------  --------  ------\n",
            "input      0.589746  -0.701648  0.394555  0.904477  1.23426  0.356815  -0.804551  0.169323  -1.50376  0.3185\n",
            "keep mask  0          0         0         1         0        0          1         1          0        0\n",
            "output     0          0         0         1.80895   0        0         -1.6091    0.338647   0        0\n",
            "---------  --------  ---------  --------  --------  -------  --------  ---------  --------  --------  ------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the [tutorial](https://triton-lang.org/main/getting-started/tutorials/04-low-memory-dropout.html) there is a more efficient way of doing the dropout. As you can see we are keeping the dropout mask stored in the memory of the GPU. One alternative is using a seeded random number generator. With this approach we can always get the mask for the backpropagation by just knowing the seed."
      ],
      "metadata": {
        "id": "aivYwjC2pr9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout(\n",
        "    input_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    seed,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "  pid = tl.program_id(0)\n",
        "  block_start_ptr = pid * BLOCK_SIZE\n",
        "  offsets = block_start_ptr + tl.arange(0, BLOCK_SIZE)\n",
        "  mask = offsets < n_elements\n",
        "  input = tl.load(input_ptr+offsets, mask=mask)\n",
        "  dropout_mask = tl.rand(seed, offsets) < (1-p)\n",
        "  output = tl.where(dropout_mask, input/(1-p), 0.0)\n",
        "  tl.store(output_ptr+offsets, output, mask=mask)\n",
        "\n",
        "def seeded_dropout(input, p, seed):\n",
        "  assert input.device == DEVICE\n",
        "  assert input.is_contiguous()\n",
        "  n_elements = input.numel()\n",
        "  output = torch.empty_like(input)\n",
        "  grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "  _seeded_dropout[grid](\n",
        "      input,\n",
        "      output,\n",
        "      n_elements,\n",
        "      p,\n",
        "      seed,\n",
        "      BLOCK_SIZE=1024,\n",
        "  )\n",
        "  return output"
      ],
      "metadata": {
        "id": "vyvPr_HWlGjE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(10, )).cuda()\n",
        "# Compare this to the baseline - dropout mask is never instantiated!\n",
        "output = seeded_dropout(x, p=0.5, seed=123)\n",
        "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
        "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
        "\n",
        "print(\n",
        "    tabulate.tabulate([\n",
        "        [\"input\"] + x.tolist(),\n",
        "        [\"output (seed = 123)\"] + output.tolist(),\n",
        "        [\"output (seed = 123)\"] + output2.tolist(),\n",
        "        [\"output (seed = 512)\"] + output3.tolist(),\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-co2R1krXaT",
        "outputId": "7b97d8a2-8c90-4912-bc3c-b1e73d9812eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------  --------  --------  --------  --------  -------  -------  --------  --------  ---------  ---------\n",
            "input                0.744358  0.673647  0.805808  0.709042  1.07801  1.33072  0.702965  -2.23653  -0.326397  -0.925518\n",
            "output (seed = 123)  1.48872   0         1.61162   1.41808   2.15601  0        1.40593   -4.47306   0          0\n",
            "output (seed = 123)  1.48872   0         1.61162   1.41808   2.15601  0        1.40593   -4.47306   0          0\n",
            "output (seed = 512)  1.48872   1.34729   0         0         2.15601  0        0         -4.47306  -0.652794  -1.85104\n",
            "-------------------  --------  --------  --------  --------  -------  -------  --------  --------  ---------  ---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise #1\n",
        "Extend the kernel to operate over a matrix and use a vector of seeds - one per row."
      ],
      "metadata": {
        "id": "RAahGJhpsjqu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout_matrix(\n",
        "    input_ptr,\n",
        "    output_ptr,\n",
        "    n_rows,\n",
        "    n_cols,\n",
        "    p,\n",
        "    seed_ptr,\n",
        "    BLOCK_SIZE_M: tl.constexpr,\n",
        "    BLOCK_SIZE_N: tl.constexpr,\n",
        "):\n",
        "    pid_m = tl.program_id(0)\n",
        "    pid_n = tl.program_id(1)\n",
        "    block_start_m = pid_m * BLOCK_SIZE_M\n",
        "    block_start_n = pid_n * BLOCK_SIZE_N\n",
        "    offsets_m = block_start_m + tl.arange(0, BLOCK_SIZE_M)\n",
        "    offsets_n = block_start_n + tl.arange(0, BLOCK_SIZE_N)\n",
        "    mask_m = offsets_m < n_rows\n",
        "    mask_n = offsets_n < n_cols\n",
        "    row_ids = tl.arange(0, BLOCK_SIZE_M)\n",
        "    seeds = tl.load(seed_ptr + row_ids, mask=mask_m)\n",
        "    input = tl.load(input_ptr + offsets_m[:, None] * n_cols + offsets_n[None, :], mask=mask_m[:, None] & mask_n[None, :], other=0.0)\n",
        "    dropout_mask = tl.rand(seeds[:, None], offsets_n[None, :]) < (1 - p)\n",
        "    output = tl.where(dropout_mask, input / (1 - p), 0.0)\n",
        "    tl.store(output_ptr + offsets_m[:, None] * n_cols + offsets_n[None, :], output, mask=mask_m[:, None] & mask_n[None, :])\n",
        "\n",
        "\n",
        "def seeded_dropout_matrix(input, p, seeds):\n",
        "    assert input.device == seeds.device == DEVICE\n",
        "    assert input.is_contiguous()\n",
        "    assert seeds.is_contiguous()\n",
        "    n_rows, n_cols = input.shape\n",
        "    output = torch.empty_like(input)\n",
        "    grid = lambda meta: (triton.cdiv(n_rows, meta['BLOCK_SIZE_M']), triton.cdiv(n_cols, meta['BLOCK_SIZE_N']))\n",
        "    _seeded_dropout_matrix[grid](\n",
        "        input,\n",
        "        output,\n",
        "        n_rows,\n",
        "        n_cols,\n",
        "        p,\n",
        "        seeds,\n",
        "        BLOCK_SIZE_M=128,\n",
        "        BLOCK_SIZE_N=128,\n",
        "    )\n",
        "    return output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBhQCcN5ygBZ",
        "outputId": "51e15bad-0049-41af-b3ec-3eed5d91af02"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "input   [[-0.7382807731628418, -1.047772765159607, -1.6961694955825806, 0.5749549865722656], [1.3147995471954346, 0.2664060890674591, 0.3009762167930603, -0.7670519948005676], [2.172617197036743, 0.2045144885778427, 0.5811920762062073, 0.7890559434890747]]\n",
            "seeds   [118, 897, 644]\n",
            "output  [[-1.4765615463256836, -2.095545530319214, -3.392338991165161, 1.1499099731445312], [2.629599094390869, 0.0, 0.6019524335861206, 0.0], [0.0, 0.0, 1.1623841524124146, 1.5781118869781494]]\n",
            "------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(3, 4)).cuda()\n",
        "seeds = torch.randint(0, 1000, size=(3,)).cuda()\n",
        "output = seeded_dropout_matrix(x, p=0.5, seeds=seeds)\n",
        "output2 = seeded_dropout_matrix(x, p=0.5, seeds=seeds)\n",
        "seeds2 = torch.randint(0, 1000, size=(3,)).cuda()\n",
        "output3 = seeded_dropout_matrix(x, p=0.5, seeds=seeds2)\n",
        "\n",
        "print(tabulate.tabulate([\n",
        "    [\"input\"] + [x.tolist()],\n",
        "    [\"seeds\"] + [seeds.tolist()],\n",
        "    [\"output\"] + [output.tolist()],\n",
        "    [\"output2\"] + [output2.tolist()],\n",
        "    [\"seeds2\"] + [seeds2.tolist()],\n",
        "    [\"output3\"] + [output3.tolist()],\n",
        "]))\n",
        "\n",
        "assert torch.equal(output, output2)\n",
        "assert not torch.equal(output, output3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgjPDTCj1JlG",
        "outputId": "6e154697-af06-4238-f63d-d2d57c656236"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
            "input    [[1.2940841913223267, 0.3524411618709564, 0.8476082682609558, -0.6345377564430237], [0.5777156949043274, 0.6289191842079163, 1.9632174968719482, -0.23515857756137848], [-0.8319748044013977, 0.6860969662666321, 1.7440965175628662, 0.7546724081039429]]\n",
            "seeds    [338, 971, 338]\n",
            "output   [[0.0, 0.0, 1.6952165365219116, -1.2690755128860474], [1.1554313898086548, 1.2578383684158325, 0.0, 0.0], [0.0, 0.0, 3.4881930351257324, 1.5093448162078857]]\n",
            "output2  [[0.0, 0.0, 1.6952165365219116, -1.2690755128860474], [1.1554313898086548, 1.2578383684158325, 0.0, 0.0], [0.0, 0.0, 3.4881930351257324, 1.5093448162078857]]\n",
            "seeds2   [10, 818, 339]\n",
            "output3  [[2.5881683826446533, 0.0, 1.6952165365219116, 0.0], [0.0, 1.2578383684158325, 0.0, 0.0], [-1.6639496088027954, 0.0, 3.4881930351257324, 0.0]]\n",
            "-------  ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iOnQ0Iww2GQs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}