{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWWYwh1pvEUe1BT2sYpDCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/casanovaalonso/TritonTutorials/blob/main/04_triton_dropout.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DHbdSNsDsHc2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd80bf5-96fa-4e31-aa0f-362493933278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting triton\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton) (3.16.1)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton\n",
            "Successfully installed triton-3.1.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install triton\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RkECxK4xeL3P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dropout Regularization\n",
        "\n",
        "Dropout is a technique to prevent overfitting in neural networks by randomly \"dropping out\" (setting to zero) a fraction of neurons during training.\n",
        "\n",
        "### 1. **Forward Pass with Dropout**\n",
        "Each neuron in a layer has a probability $ p $ of being kept:\n",
        "\n",
        "$$\n",
        "d_i \\sim \\text{Bernoulli}(p)\n",
        "$$\n",
        "\n",
        "The activations are then scaled:\n",
        "\n",
        "$$\n",
        "\\hat{\\mathbf{a}}_l = \\frac{\\mathbf{a}_l \\odot \\mathbf{d}}{(1-p)}\n",
        "$$\n",
        "\n",
        "### 2. **Backpropagation**\n",
        "During backpropagation, the gradients are computed with the dropout mask applied, ensuring correct updates.\n",
        "\n",
        "### 3. **Test Time**\n",
        "At inference time, no neurons are dropped. The output is not scaled, to account for the dropout during training.Ç"
      ],
      "metadata": {
        "id": "bKHzATYXeNWM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tabulate\n",
        "import torch\n",
        "\n",
        "import triton\n",
        "import triton.language as tl"
      ],
      "metadata": {
        "id": "UD-nX-XoeNJB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE = torch.device(f\"cuda:{torch.cuda.current_device()}\")"
      ],
      "metadata": {
        "id": "J1SWssuKlTLS"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function will work on 1D tensors\n",
        "@triton.jit\n",
        "def _dropout(\n",
        "    input_ptr,\n",
        "    input_keep_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "  pid = tl.program_id(0)\n",
        "  block_start_ptr = pid * BLOCK_SIZE\n",
        "  offsets = block_start_ptr + tl.arange(0, BLOCK_SIZE)\n",
        "  mask = offsets < n_elements\n",
        "  input = tl.load(input_ptr+offsets, mask=mask)\n",
        "  input_keep = tl.load(input_keep_ptr+offsets, mask=mask)\n",
        "  output = tl.where(input_keep, input/(1-p), 0.0)\n",
        "  tl.store(output_ptr+offsets, output, mask=mask)\n",
        "\n",
        "def dropout(input, input_keep, p):\n",
        "  assert input.device == input_keep.device == DEVICE\n",
        "  assert input.shape == input_keep.shape\n",
        "  assert input.is_contiguous()\n",
        "  assert input_keep.is_contiguous()\n",
        "  n_elements = input.numel()\n",
        "  output = torch.empty_like(input)\n",
        "  grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "  _dropout[grid](\n",
        "      input,\n",
        "      input_keep,\n",
        "      output,\n",
        "      n_elements,\n",
        "      p,\n",
        "      BLOCK_SIZE=1024,\n",
        "  )\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "CmIb6NGAfnmf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input tensor\n",
        "x = torch.randn(size=(10, )).cuda()\n",
        "# Dropout mask\n",
        "p = 0.5\n",
        "x_keep = (torch.rand(size=(10, )) > p).to(torch.int32).cuda()\n",
        "output = dropout(x, input_keep=x_keep, p=p)\n",
        "print(tabulate.tabulate([\n",
        "    [\"input\"] + x.tolist(),\n",
        "    [\"keep mask\"] + x_keep.tolist(),\n",
        "    [\"output\"] + output.tolist(),\n",
        "]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPIxri8lFuZ",
        "outputId": "0d4ce7f8-5e37-44ac-8009-c277443d7a72"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------  --------  ---------  --------  --------  -------  --------  ---------  --------  --------  ------\n",
            "input      0.589746  -0.701648  0.394555  0.904477  1.23426  0.356815  -0.804551  0.169323  -1.50376  0.3185\n",
            "keep mask  0          0         0         1         0        0          1         1          0        0\n",
            "output     0          0         0         1.80895   0        0         -1.6091    0.338647   0        0\n",
            "---------  --------  ---------  --------  --------  -------  --------  ---------  --------  --------  ------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "According to the [tutorial](https://triton-lang.org/main/getting-started/tutorials/04-low-memory-dropout.html) there is a more efficient way of doing the dropout. As you can see we are keeping the dropout mask stored in the memory of the GPU. One alternative is using a seeded random number generator. With this approach we can always get the mask for the backpropagation by just knowing the seed."
      ],
      "metadata": {
        "id": "aivYwjC2pr9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@triton.jit\n",
        "def _seeded_dropout(\n",
        "    input_ptr,\n",
        "    output_ptr,\n",
        "    n_elements,\n",
        "    p,\n",
        "    seed,\n",
        "    BLOCK_SIZE: tl.constexpr,\n",
        "):\n",
        "  pid = tl.program_id(0)\n",
        "  block_start_ptr = pid * BLOCK_SIZE\n",
        "  offsets = block_start_ptr + tl.arange(0, BLOCK_SIZE)\n",
        "  mask = offsets < n_elements\n",
        "  input = tl.load(input_ptr+offsets, mask=mask)\n",
        "  dropout_mask = tl.rand(seed, offsets) < (1-p)\n",
        "  output = tl.where(dropout_mask, input/(1-p), 0.0)\n",
        "  tl.store(output_ptr+offsets, output, mask=mask)\n",
        "\n",
        "def seeded_dropout(input, p, seed):\n",
        "  assert input.device == DEVICE\n",
        "  assert input.is_contiguous()\n",
        "  n_elements = input.numel()\n",
        "  output = torch.empty_like(input)\n",
        "  grid = lambda meta: (triton.cdiv(n_elements, meta['BLOCK_SIZE']),)\n",
        "  _seeded_dropout[grid](\n",
        "      input,\n",
        "      output,\n",
        "      n_elements,\n",
        "      p,\n",
        "      seed,\n",
        "      BLOCK_SIZE=1024,\n",
        "  )\n",
        "  return output"
      ],
      "metadata": {
        "id": "vyvPr_HWlGjE"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(size=(10, )).cuda()\n",
        "# Compare this to the baseline - dropout mask is never instantiated!\n",
        "output = seeded_dropout(x, p=0.5, seed=123)\n",
        "output2 = seeded_dropout(x, p=0.5, seed=123)\n",
        "output3 = seeded_dropout(x, p=0.5, seed=512)\n",
        "\n",
        "print(\n",
        "    tabulate.tabulate([\n",
        "        [\"input\"] + x.tolist(),\n",
        "        [\"output (seed = 123)\"] + output.tolist(),\n",
        "        [\"output (seed = 123)\"] + output2.tolist(),\n",
        "        [\"output (seed = 512)\"] + output3.tolist(),\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-co2R1krXaT",
        "outputId": "7b97d8a2-8c90-4912-bc3c-b1e73d9812eb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------  --------  --------  --------  --------  -------  -------  --------  --------  ---------  ---------\n",
            "input                0.744358  0.673647  0.805808  0.709042  1.07801  1.33072  0.702965  -2.23653  -0.326397  -0.925518\n",
            "output (seed = 123)  1.48872   0         1.61162   1.41808   2.15601  0        1.40593   -4.47306   0          0\n",
            "output (seed = 123)  1.48872   0         1.61162   1.41808   2.15601  0        1.40593   -4.47306   0          0\n",
            "output (seed = 512)  1.48872   1.34729   0         0         2.15601  0        0         -4.47306  -0.652794  -1.85104\n",
            "-------------------  --------  --------  --------  --------  -------  -------  --------  --------  ---------  ---------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BIklSP3QrhMS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}